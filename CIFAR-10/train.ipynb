{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466fbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import model as m\n",
    "import pickle\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc523d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "train_set, test_set = m.get_train_test_set(batch_size=32)\n",
    "_, valid_set = enumerate(test_set).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a9eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check device...CUDA available.\n",
      "Epoch [1], iteration 100, loss = 2.131462812423706, valid loss = 2.007209300994873\n",
      "Epoch [1], iteration 200, loss = 2.1426994800567627, valid loss = 1.9798095226287842\n",
      "Epoch [1], iteration 300, loss = 1.7713100910186768, valid loss = 1.7537716627120972\n",
      "Epoch [1], iteration 400, loss = 2.100806713104248, valid loss = 1.6513255834579468\n",
      "Epoch [1], iteration 500, loss = 1.8614041805267334, valid loss = 1.5646004676818848\n",
      "Epoch [1], iteration 600, loss = 1.9322845935821533, valid loss = 1.4689133167266846\n",
      "Epoch [1], iteration 700, loss = 1.813951849937439, valid loss = 1.4530205726623535\n",
      "Epoch [1], iteration 800, loss = 2.1157257556915283, valid loss = 1.3849804401397705\n",
      "Epoch [1], iteration 900, loss = 2.0170950889587402, valid loss = 1.471866488456726\n",
      "Epoch [1], iteration 1000, loss = 1.445304036140442, valid loss = 1.3960362672805786\n",
      "Epoch [1], iteration 1100, loss = 1.664839267730713, valid loss = 1.1806068420410156\n",
      "Epoch [1], iteration 1200, loss = 1.4864931106567383, valid loss = 1.2630575895309448\n",
      "Epoch [1], iteration 1300, loss = 1.5233622789382935, valid loss = 1.2151143550872803\n",
      "Epoch [1], iteration 1400, loss = 1.4317758083343506, valid loss = 1.2990164756774902\n",
      "Epoch [1], iteration 1500, loss = 1.2765318155288696, valid loss = 1.1613250970840454\n",
      "Epoch [1], loss = 1.7735654413890778, valid loss = 1.483376932144165\n",
      "Epoch [2], iteration 100, loss = 1.4333112239837646, valid loss = 1.214682936668396\n",
      "Epoch [2], iteration 200, loss = 1.3446956872940063, valid loss = 1.0065979957580566\n",
      "Epoch [2], iteration 300, loss = 1.6272703409194946, valid loss = 0.9967384338378906\n",
      "Epoch [2], iteration 400, loss = 1.650292158126831, valid loss = 0.900231122970581\n",
      "Epoch [2], iteration 500, loss = 1.4414830207824707, valid loss = 1.025718331336975\n",
      "Epoch [2], iteration 600, loss = 1.5724562406539917, valid loss = 0.9946839809417725\n",
      "Epoch [2], iteration 700, loss = 1.1754738092422485, valid loss = 0.9408865571022034\n",
      "Epoch [2], iteration 800, loss = 1.3156644105911255, valid loss = 0.842110812664032\n",
      "Epoch [2], iteration 900, loss = 1.3227306604385376, valid loss = 0.7644912004470825\n",
      "Epoch [2], iteration 1000, loss = 1.3732589483261108, valid loss = 0.7449949979782104\n",
      "Epoch [2], iteration 1100, loss = 1.3677270412445068, valid loss = 0.7412688136100769\n",
      "Epoch [2], iteration 1200, loss = 1.3111554384231567, valid loss = 0.9700713157653809\n",
      "Epoch [2], iteration 1300, loss = 1.3341169357299805, valid loss = 0.888582706451416\n",
      "Epoch [2], iteration 1400, loss = 1.2309057712554932, valid loss = 0.7429229021072388\n",
      "Epoch [2], iteration 1500, loss = 1.3796523809432983, valid loss = 0.8412721753120422\n",
      "Epoch [2], loss = 1.3065232467132735, valid loss = 0.9076836188634236\n",
      "Epoch [3], iteration 100, loss = 1.3331550359725952, valid loss = 0.6968594789505005\n",
      "Epoch [3], iteration 200, loss = 1.0482746362686157, valid loss = 0.6914990544319153\n",
      "Epoch [3], iteration 300, loss = 1.1071109771728516, valid loss = 0.6315325498580933\n",
      "Epoch [3], iteration 400, loss = 1.085542917251587, valid loss = 0.7017216682434082\n",
      "Epoch [3], iteration 500, loss = 1.3354707956314087, valid loss = 0.7177623510360718\n",
      "Epoch [3], iteration 600, loss = 1.0763956308364868, valid loss = 0.7008576393127441\n",
      "Epoch [3], iteration 700, loss = 1.3998607397079468, valid loss = 0.6158143877983093\n",
      "Epoch [3], iteration 800, loss = 0.9672463536262512, valid loss = 0.6694516539573669\n",
      "Epoch [3], iteration 900, loss = 0.9129936099052429, valid loss = 0.6280945539474487\n",
      "Epoch [3], iteration 1000, loss = 1.409777283668518, valid loss = 0.5295047760009766\n",
      "Epoch [3], iteration 1100, loss = 0.9196142554283142, valid loss = 0.6675848960876465\n",
      "Epoch [3], iteration 1200, loss = 1.310914397239685, valid loss = 0.6079134941101074\n",
      "Epoch [3], iteration 1300, loss = 0.7362750172615051, valid loss = 0.7494834661483765\n",
      "Epoch [3], iteration 1400, loss = 1.4365276098251343, valid loss = 0.7097949385643005\n",
      "Epoch [3], iteration 1500, loss = 1.0114672183990479, valid loss = 0.5536370873451233\n",
      "Epoch [3], loss = 1.0918379689132411, valid loss = 0.6581007997194926\n",
      "Epoch [4], iteration 100, loss = 0.4886625409126282, valid loss = 0.537243664264679\n",
      "Epoch [4], iteration 200, loss = 0.7239717841148376, valid loss = 0.6812641620635986\n",
      "Epoch [4], iteration 300, loss = 0.8763503432273865, valid loss = 0.5561546683311462\n",
      "Epoch [4], iteration 400, loss = 1.1701524257659912, valid loss = 0.7012087106704712\n",
      "Epoch [4], iteration 500, loss = 0.9495239853858948, valid loss = 0.5514405965805054\n",
      "Epoch [4], iteration 600, loss = 1.029138207435608, valid loss = 0.6022807359695435\n",
      "Epoch [4], iteration 700, loss = 1.1874475479125977, valid loss = 0.4345393180847168\n",
      "Epoch [4], iteration 800, loss = 0.8527655601501465, valid loss = 0.5833590030670166\n",
      "Epoch [4], iteration 900, loss = 1.2432057857513428, valid loss = 0.5287666916847229\n",
      "Epoch [4], iteration 1000, loss = 0.7617416977882385, valid loss = 0.51829993724823\n",
      "Epoch [4], iteration 1100, loss = 0.6526165008544922, valid loss = 0.6074286103248596\n",
      "Epoch [4], iteration 1200, loss = 0.8675261735916138, valid loss = 0.5719842910766602\n",
      "Epoch [4], iteration 1300, loss = 0.8112399578094482, valid loss = 0.5757446885108948\n",
      "Epoch [4], iteration 1400, loss = 0.9188536405563354, valid loss = 0.5599103569984436\n",
      "Epoch [4], iteration 1500, loss = 0.7459269165992737, valid loss = 0.6276138424873352\n",
      "Epoch [4], loss = 0.9407428703053365, valid loss = 0.5758159518241882\n",
      "Epoch [5], iteration 100, loss = 0.7603112459182739, valid loss = 0.5331902503967285\n",
      "Epoch [5], iteration 200, loss = 1.1138826608657837, valid loss = 0.6400948762893677\n",
      "Epoch [5], iteration 300, loss = 0.6133603453636169, valid loss = 0.6165735125541687\n",
      "Epoch [5], iteration 400, loss = 1.1322871446609497, valid loss = 0.5331236124038696\n",
      "Epoch [5], iteration 500, loss = 0.9126295447349548, valid loss = 0.6566436886787415\n",
      "Epoch [5], iteration 600, loss = 0.5820208191871643, valid loss = 0.598360538482666\n",
      "Epoch [5], iteration 700, loss = 0.8328425288200378, valid loss = 0.6330320239067078\n",
      "Epoch [5], iteration 800, loss = 0.8287844657897949, valid loss = 0.6266317367553711\n",
      "Epoch [5], iteration 900, loss = 0.9446289539337158, valid loss = 0.6507701277732849\n",
      "Epoch [5], iteration 1000, loss = 0.6209263801574707, valid loss = 0.5910585522651672\n",
      "Epoch [5], iteration 1100, loss = 0.5239669680595398, valid loss = 0.6227357983589172\n",
      "Epoch [5], iteration 1200, loss = 0.6330137252807617, valid loss = 0.607029914855957\n",
      "Epoch [5], iteration 1300, loss = 0.8847914338111877, valid loss = 0.538470983505249\n",
      "Epoch [5], iteration 1400, loss = 0.7328182458877563, valid loss = 0.4289851188659668\n",
      "Epoch [5], iteration 1500, loss = 0.6458339691162109, valid loss = 0.47482410073280334\n",
      "Epoch [5], loss = 0.8409876879864752, valid loss = 0.5834349890549978\n",
      "Epoch [6], iteration 100, loss = 0.6556326150894165, valid loss = 0.49226945638656616\n",
      "Epoch [6], iteration 200, loss = 1.2854008674621582, valid loss = 0.37967830896377563\n",
      "Epoch [6], iteration 300, loss = 0.539115846157074, valid loss = 0.3836807906627655\n",
      "Epoch [6], iteration 400, loss = 0.6817399859428406, valid loss = 0.36370790004730225\n",
      "Epoch [6], iteration 500, loss = 0.42806440591812134, valid loss = 0.5067930817604065\n",
      "Epoch [6], iteration 600, loss = 0.6739828586578369, valid loss = 0.4690375328063965\n",
      "Epoch [6], iteration 700, loss = 1.1057730913162231, valid loss = 0.5180932879447937\n",
      "Epoch [6], iteration 800, loss = 0.6697080135345459, valid loss = 0.42474305629730225\n",
      "Epoch [6], iteration 900, loss = 0.9219928979873657, valid loss = 0.5073798298835754\n",
      "Epoch [6], iteration 1000, loss = 0.8328497409820557, valid loss = 0.47528359293937683\n",
      "Epoch [6], iteration 1100, loss = 0.6916399002075195, valid loss = 0.5688636302947998\n",
      "Epoch [6], iteration 1200, loss = 1.096790075302124, valid loss = 0.34945282340049744\n",
      "Epoch [6], iteration 1300, loss = 1.0853453874588013, valid loss = 0.48188361525535583\n",
      "Epoch [6], iteration 1400, loss = 0.7577096819877625, valid loss = 0.4157086908817291\n",
      "Epoch [6], iteration 1500, loss = 0.28842660784721375, valid loss = 0.40119561553001404\n",
      "Epoch [6], loss = 0.7598348012431188, valid loss = 0.4491847475369771\n",
      "Epoch [7], iteration 100, loss = 0.5286976099014282, valid loss = 0.3360726237297058\n",
      "Epoch [7], iteration 200, loss = 0.853442907333374, valid loss = 0.43840155005455017\n",
      "Epoch [7], iteration 300, loss = 0.7210862636566162, valid loss = 0.394949734210968\n",
      "Epoch [7], iteration 400, loss = 0.5425779223442078, valid loss = 0.42348015308380127\n",
      "Epoch [7], iteration 500, loss = 0.7044883966445923, valid loss = 0.42840003967285156\n",
      "Epoch [7], iteration 600, loss = 0.8440459966659546, valid loss = 0.4116469919681549\n",
      "Epoch [7], iteration 700, loss = 0.6444476842880249, valid loss = 0.5354545712471008\n",
      "Epoch [7], iteration 800, loss = 0.36019304394721985, valid loss = 0.4680269956588745\n",
      "Epoch [7], iteration 900, loss = 0.4379667639732361, valid loss = 0.4326115548610687\n",
      "Epoch [7], iteration 1000, loss = 0.5297215580940247, valid loss = 0.483388751745224\n",
      "Epoch [7], iteration 1100, loss = 1.0536729097366333, valid loss = 0.4525471031665802\n",
      "Epoch [7], iteration 1200, loss = 0.8546990156173706, valid loss = 0.49030742049217224\n",
      "Epoch [7], iteration 1300, loss = 0.6723297834396362, valid loss = 0.44735026359558105\n",
      "Epoch [7], iteration 1400, loss = 0.6525439620018005, valid loss = 0.330592542886734\n",
      "Epoch [7], iteration 1500, loss = 0.4734203815460205, valid loss = 0.33504894375801086\n",
      "Epoch [7], loss = 0.7027599450989709, valid loss = 0.42721861600875854\n",
      "Epoch [8], iteration 100, loss = 0.49926701188087463, valid loss = 0.32894185185432434\n",
      "Epoch [8], iteration 200, loss = 0.5884456634521484, valid loss = 0.44567739963531494\n",
      "Epoch [8], iteration 300, loss = 0.7803192734718323, valid loss = 0.5174269676208496\n",
      "Epoch [8], iteration 400, loss = 0.44721508026123047, valid loss = 0.3916544020175934\n",
      "Epoch [8], iteration 500, loss = 0.6410073041915894, valid loss = 0.3394699990749359\n",
      "Epoch [8], iteration 600, loss = 0.5348219275474548, valid loss = 0.379922479391098\n",
      "Epoch [8], iteration 700, loss = 0.7402633428573608, valid loss = 0.520740270614624\n",
      "Epoch [8], iteration 800, loss = 0.2776238024234772, valid loss = 0.4085518419742584\n",
      "Epoch [8], iteration 900, loss = 0.6093770265579224, valid loss = 0.5036145448684692\n",
      "Epoch [8], iteration 1000, loss = 0.6549763083457947, valid loss = 0.4275728762149811\n",
      "Epoch [8], iteration 1100, loss = 0.6871153712272644, valid loss = 0.3177949786186218\n",
      "Epoch [8], iteration 1200, loss = 0.6933990716934204, valid loss = 0.3494800329208374\n",
      "Epoch [8], iteration 1300, loss = 0.5476258397102356, valid loss = 0.4300791919231415\n",
      "Epoch [8], iteration 1400, loss = 0.8526066541671753, valid loss = 0.45129474997520447\n",
      "Epoch [8], iteration 1500, loss = 0.7565001249313354, valid loss = 0.4378584623336792\n",
      "Epoch [8], loss = 0.6448404077185474, valid loss = 0.41667200326919557\n",
      "Epoch [9], iteration 100, loss = 0.2097022980451584, valid loss = 0.42701372504234314\n",
      "Epoch [9], iteration 200, loss = 0.7926032543182373, valid loss = 0.3425169885158539\n",
      "Epoch [9], iteration 300, loss = 0.40520548820495605, valid loss = 0.3852130174636841\n",
      "Epoch [9], iteration 400, loss = 0.7858891487121582, valid loss = 0.46283242106437683\n",
      "Epoch [9], iteration 500, loss = 0.47210758924484253, valid loss = 0.3893023729324341\n",
      "Epoch [9], iteration 600, loss = 0.5626099109649658, valid loss = 0.28411635756492615\n",
      "Epoch [9], iteration 700, loss = 0.7997116446495056, valid loss = 0.4052046239376068\n",
      "Epoch [9], iteration 800, loss = 0.4880566895008087, valid loss = 0.32134753465652466\n",
      "Epoch [9], iteration 900, loss = 0.5673720240592957, valid loss = 0.37667563557624817\n",
      "Epoch [9], iteration 1000, loss = 0.40523964166641235, valid loss = 0.3379037380218506\n",
      "Epoch [9], iteration 1100, loss = 0.5594528913497925, valid loss = 0.34587687253952026\n",
      "Epoch [9], iteration 1200, loss = 0.6158310174942017, valid loss = 0.28636637330055237\n",
      "Epoch [9], iteration 1300, loss = 0.2944771349430084, valid loss = 0.3315070867538452\n",
      "Epoch [9], iteration 1400, loss = 0.4989948272705078, valid loss = 0.4411691427230835\n",
      "Epoch [9], iteration 1500, loss = 0.764289379119873, valid loss = 0.41992107033729553\n",
      "Epoch [9], loss = 0.6065261250532215, valid loss = 0.37046446402867633\n",
      "Epoch [10], iteration 100, loss = 0.4176425337791443, valid loss = 0.35659852623939514\n",
      "Epoch [10], iteration 200, loss = 0.7617695927619934, valid loss = 0.3602208197116852\n",
      "Epoch [10], iteration 300, loss = 0.5978350043296814, valid loss = 0.2970990538597107\n",
      "Epoch [10], iteration 400, loss = 0.7314251065254211, valid loss = 0.22165736556053162\n",
      "Epoch [10], iteration 500, loss = 0.6710565686225891, valid loss = 0.38058018684387207\n",
      "Epoch [10], iteration 600, loss = 0.8291969299316406, valid loss = 0.3953562378883362\n",
      "Epoch [10], iteration 700, loss = 0.3323206603527069, valid loss = 0.3859049677848816\n",
      "Epoch [10], iteration 800, loss = 0.6498527526855469, valid loss = 0.39205867052078247\n",
      "Epoch [10], iteration 900, loss = 0.7107831239700317, valid loss = 0.23373278975486755\n",
      "Epoch [10], iteration 1000, loss = 0.38821759819984436, valid loss = 0.30443066358566284\n",
      "Epoch [10], iteration 1100, loss = 0.3858969509601593, valid loss = 0.2606884837150574\n",
      "Epoch [10], iteration 1200, loss = 0.49576759338378906, valid loss = 0.3743598163127899\n",
      "Epoch [10], iteration 1300, loss = 0.9519206285476685, valid loss = 0.3674429655075073\n",
      "Epoch [10], iteration 1400, loss = 0.650960385799408, valid loss = 0.2951498329639435\n",
      "Epoch [10], iteration 1500, loss = 0.7878057956695557, valid loss = 0.3481278121471405\n",
      "Epoch [10], loss = 0.5646629464870375, valid loss = 0.3315605461597443\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model, loss, loss_epoch, loss_valid = train(train_set,\n",
    "                                                valid_set,\n",
    "                                                optim='SGD',\n",
    "                                                #pool='Max',\n",
    "                                                layers=[\"Conv\",\"ReLU\", \"MaxPool\", \"Norm\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\"MaxPool\", \n",
    "                                                        \"Flatten\",\n",
    "                                                        \"Linear\", \"ReLU\", \"Drop\",\n",
    "                                                        \"Linear\", \"ReLU\", \"Drop\",\n",
    "                                                        \"Linear\"],\n",
    "                                                channel_list=[16, 256, 256, 128],#[16, 64, 128],\n",
    "                                                linear_list=[1000, 1000, 800],#[1000, 800],\n",
    "                                                num_epochs=10,\n",
    "                                                model=None)\"\"\"\n",
    "\"\"\"model, loss, loss_epoch, loss_valid = train(train_set,\n",
    "                                                valid_set,\n",
    "                                                optim='SGD',\n",
    "                                                #pool='Max',\n",
    "                                                layers=[\"Conv\",\"ReLU\", \"MaxPool\", \"Norm\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\"MaxPool\", \n",
    "                                                        \"Flatten\",\n",
    "                                                        \"Linear\", \"ReLU\", \"Drop\",\n",
    "                                                        \"Linear\", \"ReLU\",\"Drop\",\n",
    "                                                        \"Linear\"],\n",
    "                                                channel_list=[16, 256, 256, 128],#[16, 64, 128],\n",
    "                                                linear_list=[1000, 1000, 800],#[1000, 800],\n",
    "                                                num_epochs=20,\n",
    "                                                model=None)\"\"\"\n",
    "model, loss, loss_epoch, loss_valid = train(train_set,\n",
    "                                                valid_set,\n",
    "                                                optim='Adam',\n",
    "                                                #pool='Max',\n",
    "                                                layers=[\"Conv\", \"ReLU\",\"MaxPool\", \"Norm\",\n",
    "                                                        #\"Conv\", \"ReLU\",\"MaxPool\", \"Norm\",\n",
    "                                                        \"Conv\", \"ReLU\",\n",
    "                                                        \"Conv\", \"ReLU\",\n",
    "                                                        \"Conv\", \"ReLU\",\"MaxPool\",\n",
    "                                                        \"Flatten\",\n",
    "                                                        \"Linear\", \"ReLU\",\"Drop\",\n",
    "                                                        \"Linear\", \"ReLU\",\"Drop\",\n",
    "                                                        \"Linear\", \"ReLU\",\"Drop\",\n",
    "                                                        \"Linear\"\n",
    "                                                        ],\n",
    "                                                #channel_list=[64, 64, 128, 256],#[16, 64, 128],\n",
    "                                                channel_list=[96, 384,256,  256],\n",
    "                                                #channel_list=[16, 128,  256],\n",
    "                                                linear_list=[1000, 1000, 800, 600],#[1000, 800],\n",
    "                                                #linear_list=[1000, 800],#[1000, 800]\n",
    "                                                num_epochs=20,\n",
    "                                                model=None)\n",
    "with open('./models/model.pickle', 'wb') as fp:\n",
    "    pickle.dump(model, fp)\n",
    "with open('./figures/loss.pickle', 'wb') as fp:\n",
    "    pickle.dump((loss, loss_epoch, loss_valid), fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
