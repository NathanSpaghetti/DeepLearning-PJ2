{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466fbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import model as m\n",
    "import pickle\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc523d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "train_set, test_set = m.get_train_test_set(batch_size=32)\n",
    "_, valid_set = enumerate(test_set).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a9eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu as device.\n",
      "Now count_conv [0]\n",
      "channels:[3, 16, 256, 256, 128]\n",
      "Now count_conv [1]\n",
      "channels:[3, 16, 256, 256, 128]\n",
      "Now count_conv [2]\n",
      "channels:[3, 16, 256, 256, 128]\n",
      "Now count_conv [3]\n",
      "channels:[3, 16, 256, 256, 128]\n",
      "Epoch [1], iteration 100, loss = 2.7788703441619873, valid loss = 2.644836664199829\n",
      "Epoch [1], iteration 200, loss = 2.315477132797241, valid loss = 2.2836456298828125\n",
      "Epoch [1], iteration 300, loss = 1.8592808246612549, valid loss = 1.9287561178207397\n",
      "Epoch [1], iteration 400, loss = 2.1015431880950928, valid loss = 2.030041217803955\n",
      "Epoch [1], iteration 500, loss = 2.190201759338379, valid loss = 1.982025384902954\n",
      "Epoch [1], iteration 600, loss = 1.7800617218017578, valid loss = 1.7007036209106445\n",
      "Epoch [1], iteration 700, loss = 1.7148044109344482, valid loss = 1.844132661819458\n",
      "Epoch [1], iteration 800, loss = 1.7308472394943237, valid loss = 2.0109426975250244\n",
      "Epoch [1], iteration 900, loss = 1.7299476861953735, valid loss = 1.5993801355361938\n",
      "Epoch [1], iteration 1000, loss = 1.7409837245941162, valid loss = 1.7495684623718262\n",
      "Epoch [1], iteration 1100, loss = 1.445080280303955, valid loss = 1.5537197589874268\n",
      "Epoch [1], iteration 1200, loss = 1.8708418607711792, valid loss = 1.436924695968628\n",
      "Epoch [1], iteration 1300, loss = 1.5540106296539307, valid loss = 1.2884948253631592\n",
      "Epoch [1], iteration 1400, loss = 1.6812844276428223, valid loss = 1.4418572187423706\n",
      "Epoch [1], iteration 1500, loss = 1.5288724899291992, valid loss = 1.5623222589492798\n",
      "Epoch [1], loss = 2.0844843142778537, valid loss = 1.80382342338562\n",
      "Epoch [2], iteration 100, loss = 1.2496315240859985, valid loss = 1.3517365455627441\n",
      "Epoch [2], iteration 200, loss = 1.7531473636627197, valid loss = 1.3040759563446045\n",
      "Epoch [2], iteration 300, loss = 1.7744758129119873, valid loss = 1.3677406311035156\n",
      "Epoch [2], iteration 400, loss = 1.6562918424606323, valid loss = 1.3080583810806274\n",
      "Epoch [2], iteration 500, loss = 1.5605374574661255, valid loss = 1.2505903244018555\n",
      "Epoch [2], iteration 600, loss = 1.637618064880371, valid loss = 1.302612066268921\n",
      "Epoch [2], iteration 700, loss = 1.2969152927398682, valid loss = 1.0335949659347534\n",
      "Epoch [2], iteration 800, loss = 1.434930682182312, valid loss = 1.2185494899749756\n",
      "Epoch [2], iteration 900, loss = 0.9906980991363525, valid loss = 1.0588384866714478\n",
      "Epoch [2], iteration 1000, loss = 1.3440016508102417, valid loss = 1.1036889553070068\n",
      "Epoch [2], iteration 1100, loss = 1.445893406867981, valid loss = 1.1371649503707886\n",
      "Epoch [2], iteration 1200, loss = 1.4470046758651733, valid loss = 1.055916666984558\n",
      "Epoch [2], iteration 1300, loss = 1.22909677028656, valid loss = 0.9290761351585388\n",
      "Epoch [2], iteration 1400, loss = 1.405768632888794, valid loss = 0.9877726435661316\n",
      "Epoch [2], iteration 1500, loss = 1.3067790269851685, valid loss = 1.132746934890747\n",
      "Epoch [2], loss = 1.4767931013708304, valid loss = 1.1694775422414143\n",
      "Epoch [3], iteration 100, loss = 1.231940507888794, valid loss = 1.0018192529678345\n",
      "Epoch [3], iteration 200, loss = 1.2737724781036377, valid loss = 1.347096562385559\n",
      "Epoch [3], iteration 300, loss = 1.2422987222671509, valid loss = 0.9042258858680725\n",
      "Epoch [3], iteration 400, loss = 1.1451406478881836, valid loss = 1.1417509317398071\n",
      "Epoch [3], iteration 500, loss = 1.2309489250183105, valid loss = 0.9049794673919678\n",
      "Epoch [3], iteration 600, loss = 1.3766717910766602, valid loss = 0.9428504109382629\n",
      "Epoch [3], iteration 700, loss = 1.494921326637268, valid loss = 1.0850024223327637\n",
      "Epoch [3], iteration 800, loss = 1.0304055213928223, valid loss = 0.9100350141525269\n",
      "Epoch [3], iteration 900, loss = 1.306471824645996, valid loss = 0.8693966269493103\n",
      "Epoch [3], iteration 1000, loss = 1.5710220336914062, valid loss = 0.9372813105583191\n",
      "Epoch [3], iteration 1100, loss = 1.4368889331817627, valid loss = 0.9820838570594788\n",
      "Epoch [3], iteration 1200, loss = 1.6923469305038452, valid loss = 0.8712467551231384\n",
      "Epoch [3], iteration 1300, loss = 1.4777990579605103, valid loss = 0.8811132311820984\n",
      "Epoch [3], iteration 1400, loss = 1.0226415395736694, valid loss = 0.907135546207428\n",
      "Epoch [3], iteration 1500, loss = 1.1198736429214478, valid loss = 0.7359553575515747\n",
      "Epoch [3], loss = 1.2724699189627848, valid loss = 0.9614648421605428\n",
      "Epoch [4], iteration 100, loss = 1.2442419528961182, valid loss = 0.8072710037231445\n",
      "Epoch [4], iteration 200, loss = 1.0925025939941406, valid loss = 0.7455930113792419\n",
      "Epoch [4], iteration 300, loss = 1.0986446142196655, valid loss = 0.7794807553291321\n",
      "Epoch [4], iteration 400, loss = 0.9991519451141357, valid loss = 0.6786197423934937\n",
      "Epoch [4], iteration 500, loss = 1.4308964014053345, valid loss = 0.8332158923149109\n",
      "Epoch [4], iteration 600, loss = 1.1860456466674805, valid loss = 0.938187301158905\n",
      "Epoch [4], iteration 700, loss = 1.0074119567871094, valid loss = 0.6851221323013306\n",
      "Epoch [4], iteration 800, loss = 0.9982618093490601, valid loss = 0.9016780853271484\n",
      "Epoch [4], iteration 900, loss = 1.3829455375671387, valid loss = 0.7472114562988281\n",
      "Epoch [4], iteration 1000, loss = 1.1983880996704102, valid loss = 0.8660733699798584\n",
      "Epoch [4], iteration 1100, loss = 1.2135062217712402, valid loss = 0.7100919485092163\n",
      "Epoch [4], iteration 1200, loss = 1.2681978940963745, valid loss = 0.5340238809585571\n",
      "Epoch [4], iteration 1300, loss = 0.9033025503158569, valid loss = 0.7062980532646179\n",
      "Epoch [4], iteration 1400, loss = 1.3197110891342163, valid loss = 0.710824191570282\n",
      "Epoch [4], iteration 1500, loss = 1.3281275033950806, valid loss = 0.6692327260971069\n",
      "Epoch [4], loss = 1.1113254072684473, valid loss = 0.7541949033737183\n",
      "Epoch [5], iteration 100, loss = 0.9639918208122253, valid loss = 0.765609622001648\n",
      "Epoch [5], iteration 200, loss = 1.0640816688537598, valid loss = 0.6419380307197571\n",
      "Epoch [5], iteration 300, loss = 0.8350019454956055, valid loss = 0.6180975437164307\n",
      "Epoch [5], iteration 400, loss = 1.094680905342102, valid loss = 0.6870619654655457\n",
      "Epoch [5], iteration 500, loss = 1.048661231994629, valid loss = 0.699123740196228\n",
      "Epoch [5], iteration 600, loss = 0.8859212398529053, valid loss = 0.48899540305137634\n",
      "Epoch [5], iteration 700, loss = 1.2076339721679688, valid loss = 0.8025484085083008\n",
      "Epoch [5], iteration 800, loss = 1.0918128490447998, valid loss = 0.672913134098053\n",
      "Epoch [5], iteration 900, loss = 0.9948225617408752, valid loss = 0.613530695438385\n",
      "Epoch [5], iteration 1000, loss = 0.9228050112724304, valid loss = 0.628261923789978\n",
      "Epoch [5], iteration 1100, loss = 1.006006121635437, valid loss = 0.6004548668861389\n",
      "Epoch [5], iteration 1200, loss = 0.6914082765579224, valid loss = 0.5831719040870667\n",
      "Epoch [5], iteration 1300, loss = 0.6711087226867676, valid loss = 0.6711600422859192\n",
      "Epoch [5], iteration 1400, loss = 1.2292757034301758, valid loss = 0.6200763583183289\n",
      "Epoch [5], iteration 1500, loss = 0.7639459371566772, valid loss = 0.6483786106109619\n",
      "Epoch [5], loss = 0.9921510554587925, valid loss = 0.6494214832782745\n",
      "Epoch [6], iteration 100, loss = 0.7230475544929504, valid loss = 0.6192402243614197\n",
      "Epoch [6], iteration 200, loss = 0.8758581876754761, valid loss = 0.5677993297576904\n",
      "Epoch [6], iteration 300, loss = 0.7734671235084534, valid loss = 0.7583303451538086\n",
      "Epoch [6], iteration 400, loss = 1.1448909044265747, valid loss = 0.7881258130073547\n",
      "Epoch [6], iteration 500, loss = 1.049214482307434, valid loss = 0.6368973255157471\n",
      "Epoch [6], iteration 600, loss = 1.0578875541687012, valid loss = 0.6127465963363647\n",
      "Epoch [6], iteration 700, loss = 1.0005706548690796, valid loss = 0.5805324912071228\n",
      "Epoch [6], iteration 800, loss = 0.700881838798523, valid loss = 0.4886687994003296\n",
      "Epoch [6], iteration 900, loss = 0.8932889699935913, valid loss = 0.6748121976852417\n",
      "Epoch [6], iteration 1000, loss = 1.0980738401412964, valid loss = 0.6213985085487366\n",
      "Epoch [6], iteration 1100, loss = 0.8333803415298462, valid loss = 0.49817490577697754\n",
      "Epoch [6], iteration 1200, loss = 1.0394309759140015, valid loss = 0.5067877173423767\n",
      "Epoch [6], iteration 1300, loss = 0.9765084385871887, valid loss = 0.4553177058696747\n",
      "Epoch [6], iteration 1400, loss = 0.77074134349823, valid loss = 0.4431709349155426\n",
      "Epoch [6], iteration 1500, loss = 0.9842358827590942, valid loss = 0.5379291772842407\n",
      "Epoch [6], loss = 0.896328445550195, valid loss = 0.5859954714775085\n",
      "Epoch [7], iteration 100, loss = 0.9185479879379272, valid loss = 0.4388050138950348\n",
      "Epoch [7], iteration 200, loss = 1.2229825258255005, valid loss = 0.6269394755363464\n",
      "Epoch [7], iteration 300, loss = 0.9380268454551697, valid loss = 0.44242215156555176\n",
      "Epoch [7], iteration 400, loss = 0.728538453578949, valid loss = 0.5433481931686401\n",
      "Epoch [7], iteration 500, loss = 0.6607903242111206, valid loss = 0.543030321598053\n",
      "Epoch [7], iteration 600, loss = 0.8301305174827576, valid loss = 0.564354419708252\n",
      "Epoch [7], iteration 700, loss = 0.6813833117485046, valid loss = 0.5274595022201538\n",
      "Epoch [7], iteration 800, loss = 0.7329785227775574, valid loss = 0.49002978205680847\n",
      "Epoch [7], iteration 900, loss = 0.7517004013061523, valid loss = 0.5510430335998535\n",
      "Epoch [7], iteration 1000, loss = 0.5795775651931763, valid loss = 0.5328447818756104\n",
      "Epoch [7], iteration 1100, loss = 0.8127328753471375, valid loss = 0.6848337054252625\n",
      "Epoch [7], iteration 1200, loss = 0.6544694900512695, valid loss = 0.5923068523406982\n",
      "Epoch [7], iteration 1300, loss = 0.8954843282699585, valid loss = 0.5877248048782349\n",
      "Epoch [7], iteration 1400, loss = 0.981484055519104, valid loss = 0.5141869187355042\n",
      "Epoch [7], iteration 1500, loss = 0.8456572890281677, valid loss = 0.47635123133659363\n",
      "Epoch [7], loss = 0.8154282032375677, valid loss = 0.5410453458627065\n",
      "Epoch [8], iteration 100, loss = 0.8682445287704468, valid loss = 0.41029661893844604\n",
      "Epoch [8], iteration 200, loss = 1.310683012008667, valid loss = 0.4025861620903015\n",
      "Epoch [8], iteration 300, loss = 0.5320209264755249, valid loss = 0.3525368273258209\n",
      "Epoch [8], iteration 400, loss = 0.6826162338256836, valid loss = 0.4111937880516052\n",
      "Epoch [8], iteration 500, loss = 1.034049153327942, valid loss = 0.3788773715496063\n",
      "Epoch [8], iteration 600, loss = 0.5775930881500244, valid loss = 0.4521034359931946\n",
      "Epoch [8], iteration 700, loss = 0.6336513161659241, valid loss = 0.3341299891471863\n",
      "Epoch [8], iteration 800, loss = 0.4662174582481384, valid loss = 0.33650386333465576\n",
      "Epoch [8], iteration 900, loss = 0.6882613301277161, valid loss = 0.38034117221832275\n",
      "Epoch [8], iteration 1000, loss = 0.7691699862480164, valid loss = 0.35271701216697693\n",
      "Epoch [8], iteration 1100, loss = 0.5322608351707458, valid loss = 0.4440707862377167\n",
      "Epoch [8], iteration 1200, loss = 0.6252182722091675, valid loss = 0.32079094648361206\n",
      "Epoch [8], iteration 1300, loss = 0.8292231559753418, valid loss = 0.3344522714614868\n",
      "Epoch [8], iteration 1400, loss = 0.6794276833534241, valid loss = 0.21040087938308716\n",
      "Epoch [8], iteration 1500, loss = 0.7380695939064026, valid loss = 0.34732285141944885\n",
      "Epoch [8], loss = 0.7475283568819135, valid loss = 0.36455493172009784\n",
      "Epoch [9], iteration 100, loss = 1.1796879768371582, valid loss = 0.3236633539199829\n",
      "Epoch [9], iteration 200, loss = 0.9590163230895996, valid loss = 0.3881766200065613\n",
      "Epoch [9], iteration 300, loss = 0.46157678961753845, valid loss = 0.3021613359451294\n",
      "Epoch [9], iteration 400, loss = 0.6001010537147522, valid loss = 0.30629172921180725\n",
      "Epoch [9], iteration 500, loss = 0.8126505017280579, valid loss = 0.3885393440723419\n",
      "Epoch [9], iteration 600, loss = 0.6161724328994751, valid loss = 0.39874109625816345\n",
      "Epoch [9], iteration 700, loss = 0.720366358757019, valid loss = 0.38486984372138977\n",
      "Epoch [9], iteration 800, loss = 0.8559765815734863, valid loss = 0.4251113831996918\n",
      "Epoch [9], iteration 900, loss = 0.48792392015457153, valid loss = 0.2930862009525299\n",
      "Epoch [9], iteration 1000, loss = 0.8258088827133179, valid loss = 0.38742387294769287\n",
      "Epoch [9], iteration 1100, loss = 0.4990287125110626, valid loss = 0.40954381227493286\n",
      "Epoch [9], iteration 1200, loss = 0.7024269104003906, valid loss = 0.40729308128356934\n",
      "Epoch [9], iteration 1300, loss = 0.6581021547317505, valid loss = 0.2798996567726135\n",
      "Epoch [9], iteration 1400, loss = 0.4941875636577606, valid loss = 0.36786508560180664\n",
      "Epoch [9], iteration 1500, loss = 0.285964697599411, valid loss = 0.31823113560676575\n",
      "Epoch [9], loss = 0.7022509421397689, valid loss = 0.35872650345166524\n",
      "Epoch [10], iteration 100, loss = 0.5587289333343506, valid loss = 0.31772613525390625\n",
      "Epoch [10], iteration 200, loss = 0.6620122194290161, valid loss = 0.27863171696662903\n",
      "Epoch [10], iteration 300, loss = 0.4282003939151764, valid loss = 0.2892782688140869\n",
      "Epoch [10], iteration 400, loss = 1.1122539043426514, valid loss = 0.3430293798446655\n",
      "Epoch [10], iteration 500, loss = 1.0364718437194824, valid loss = 0.3063105344772339\n",
      "Epoch [10], iteration 600, loss = 0.4291764795780182, valid loss = 0.5459759831428528\n",
      "Epoch [10], iteration 700, loss = 0.3311156630516052, valid loss = 0.22552433609962463\n",
      "Epoch [10], iteration 800, loss = 0.43531373143196106, valid loss = 0.24816004931926727\n",
      "Epoch [10], iteration 900, loss = 0.6758480072021484, valid loss = 0.21356146037578583\n",
      "Epoch [10], iteration 1000, loss = 0.5348249077796936, valid loss = 0.25207456946372986\n",
      "Epoch [10], iteration 1100, loss = 0.6855464577674866, valid loss = 0.342260479927063\n",
      "Epoch [10], iteration 1200, loss = 0.6679103374481201, valid loss = 0.3465733528137207\n",
      "Epoch [10], iteration 1300, loss = 0.9631227254867554, valid loss = 0.39147403836250305\n",
      "Epoch [10], iteration 1400, loss = 0.4523770213127136, valid loss = 0.31172335147857666\n",
      "Epoch [10], iteration 1500, loss = 0.7350192070007324, valid loss = 0.33495715260505676\n",
      "Epoch [10], loss = 0.6609351409030738, valid loss = 0.3164840539296468\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model, loss, loss_epoch, loss_valid = train(train_set,\n",
    "                                                valid_set,\n",
    "                                                optim='SGD',\n",
    "                                                #pool='Max',\n",
    "                                                layers=[\"Conv\",\"ReLU\", \"MaxPool\", \"Norm\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\"MaxPool\", \n",
    "                                                        \"Flatten\",\n",
    "                                                        \"Linear\", \"ReLU\", \"Drop\",\n",
    "                                                        \"Linear\", \"ReLU\", \"Drop\",\n",
    "                                                        \"Linear\"],\n",
    "                                                channel_list=[16, 256, 256, 128],#[16, 64, 128],\n",
    "                                                linear_list=[1000, 1000, 800],#[1000, 800],\n",
    "                                                num_epochs=10,\n",
    "                                                model=None)\"\"\"\n",
    "model, loss, loss_epoch, loss_valid = train(train_set,\n",
    "                                                valid_set,\n",
    "                                                optim='SGD',\n",
    "                                                #pool='Max',\n",
    "                                                layers=[\"Conv\",\"ReLU\", \"MaxPool\", \"Norm\",\n",
    "                                                        \"Conv\",\"ReLU\",\n",
    "                                                        \"Conv\",\"ReLU\",\"MaxPool\", \n",
    "                                                        \"Flatten\",\n",
    "                                                        \"Linear\", \"ReLU\", \"Drop\",\n",
    "                                                        \"Linear\"],\n",
    "                                                channel_list=[16, 128, 256],#[16, 64, 128],\n",
    "                                                linear_list=[1000, 800],#[1000, 800],\n",
    "                                                num_epochs=10,\n",
    "                                                model=None)\n",
    "with open('./models/model.pickle', 'wb') as fp:\n",
    "    pickle.dump(model, fp)\n",
    "with open('./figures/loss.pickle', 'wb') as fp:\n",
    "    pickle.dump((loss, loss_epoch, loss_valid), fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
